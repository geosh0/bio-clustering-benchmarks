{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05260183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import warnings\n",
    "import scipy.sparse\n",
    "\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# DL Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D , MaxPooling2D ,Dropout , Flatten , Dense ,BatchNormalization ,Concatenate ,Input \n",
    "from keras.models import Sequential ,Model\n",
    "import json\n",
    "\n",
    "# other libraries\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, TruncatedSVD  \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.ensemble import RandomForestClassifier # Added RandomForestClassifier\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score, adjusted_rand_score # Changed metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score # Import classification metrics\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, LabelEncoder\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from sklearn.metrics import adjusted_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import iqr # For Silverman's rule\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# RLAC MODEL\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.signal import find_peaks  \n",
    "from sklearn.neighbors import KernelDensity  \n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
    "from scipy import stats\n",
    "from scipy.special import eval_hermitenorm  # For normalized Hermite polynomials H_n(x)\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import (adjusted_mutual_info_score, adjusted_rand_score, \n",
    "                             homogeneity_score, completeness_score, v_measure_score,\n",
    "                             fowlkes_mallows_score, silhouette_score, calinski_harabasz_score,\n",
    "                             davies_bouldin_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c1cde-1aa2-465e-a7ef-feb0197869a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"yasserhessein/anuran-calls-mfccs\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88fd39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.554504</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.443451</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.021860</td>\n",
       "      <td>-0.079860</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517273</td>\n",
       "      <td>-0.370574</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.402890</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.101892</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.582557</td>\n",
       "      <td>-0.343237</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.385596</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.080425</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.519497</td>\n",
       "      <td>-0.307553</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>-0.096895</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508833</td>\n",
       "      <td>-0.324106</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>0.058874</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>0.072983</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.087910</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1          1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2          1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3          1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4          1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7190       1.0 -0.554504 -0.337717  0.035533  0.034511  0.443451  0.093889   \n",
       "7191       1.0 -0.517273 -0.370574  0.030673  0.068097  0.402890  0.096628   \n",
       "7192       1.0 -0.582557 -0.343237  0.029468  0.064179  0.385596  0.114905   \n",
       "7193       1.0 -0.519497 -0.307553 -0.004922  0.072865  0.377131  0.086866   \n",
       "7194       1.0 -0.508833 -0.324106  0.062068  0.078211  0.397188  0.094596   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
       "0    -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568   \n",
       "1    -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303   \n",
       "2    -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722   \n",
       "3    -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498   \n",
       "4    -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7190 -0.100753  0.037087  0.081075  ...  0.069430  0.071001  0.021591   \n",
       "7191 -0.116460  0.063727  0.089034  ...  0.061127  0.068978  0.017745   \n",
       "7192 -0.103317  0.070370  0.081317  ...  0.082474  0.077771 -0.009688   \n",
       "7193 -0.115799  0.056979  0.089316  ...  0.051796  0.069073  0.017963   \n",
       "7194 -0.117672  0.058874  0.076180  ...  0.061455  0.072983 -0.003980   \n",
       "\n",
       "      MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus  \\\n",
       "0     0.057684  0.118680  0.014038  Leptodactylidae  Adenomera   \n",
       "1     0.020140  0.082263  0.029056  Leptodactylidae  Adenomera   \n",
       "2    -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera   \n",
       "3    -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera   \n",
       "4    -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera   \n",
       "...        ...       ...       ...              ...        ...   \n",
       "7190  0.052449 -0.021860 -0.079860          Hylidae     Scinax   \n",
       "7191  0.046461 -0.015418 -0.101892          Hylidae     Scinax   \n",
       "7192  0.027834 -0.000531 -0.080425          Hylidae     Scinax   \n",
       "7193  0.041803 -0.027911 -0.096895          Hylidae     Scinax   \n",
       "7194  0.031560 -0.029355 -0.087910          Hylidae     Scinax   \n",
       "\n",
       "             Species  RecordID  \n",
       "0     AdenomeraAndre         1  \n",
       "1     AdenomeraAndre         1  \n",
       "2     AdenomeraAndre         1  \n",
       "3     AdenomeraAndre         1  \n",
       "4     AdenomeraAndre         1  \n",
       "...              ...       ...  \n",
       "7190     ScinaxRuber        60  \n",
       "7191     ScinaxRuber        60  \n",
       "7192     ScinaxRuber        60  \n",
       "7193     ScinaxRuber        60  \n",
       "7194     ScinaxRuber        60  \n",
       "\n",
       "[7195 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"\\.cache\\kagglehub\\datasets\\yasserhessein\\anuran-calls-mfccs\\versions\\2\\Frogs_MFCCs.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e03448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7195 entries, 0 to 7194\n",
      "Data columns (total 26 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   MFCCs_ 1  7195 non-null   float64\n",
      " 1   MFCCs_ 2  7195 non-null   float64\n",
      " 2   MFCCs_ 3  7195 non-null   float64\n",
      " 3   MFCCs_ 4  7195 non-null   float64\n",
      " 4   MFCCs_ 5  7195 non-null   float64\n",
      " 5   MFCCs_ 6  7195 non-null   float64\n",
      " 6   MFCCs_ 7  7195 non-null   float64\n",
      " 7   MFCCs_ 8  7195 non-null   float64\n",
      " 8   MFCCs_ 9  7195 non-null   float64\n",
      " 9   MFCCs_10  7195 non-null   float64\n",
      " 10  MFCCs_11  7195 non-null   float64\n",
      " 11  MFCCs_12  7195 non-null   float64\n",
      " 12  MFCCs_13  7195 non-null   float64\n",
      " 13  MFCCs_14  7195 non-null   float64\n",
      " 14  MFCCs_15  7195 non-null   float64\n",
      " 15  MFCCs_16  7195 non-null   float64\n",
      " 16  MFCCs_17  7195 non-null   float64\n",
      " 17  MFCCs_18  7195 non-null   float64\n",
      " 18  MFCCs_19  7195 non-null   float64\n",
      " 19  MFCCs_20  7195 non-null   float64\n",
      " 20  MFCCs_21  7195 non-null   float64\n",
      " 21  MFCCs_22  7195 non-null   float64\n",
      " 22  Family    7195 non-null   object \n",
      " 23  Genus     7195 non-null   object \n",
      " 24  Species   7195 non-null   object \n",
      " 25  RecordID  7195 non-null   int64  \n",
      "dtypes: float64(22), int64(1), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccd1c6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame Info:\n",
      "Shape: (7195, 26)\n",
      "\n",
      "Step 1: Removing 'RecordID' column...\n",
      "'RecordID' column removed.\n",
      "DataFrame shape after removing RecordID: (7195, 25)\n",
      "\n",
      "Step 2: Separating features (X) and labels (y_labels)...\n",
      "Features DataFrame X shape: (7195, 22)\n",
      "Labels DataFrame y_labels shape: (7195, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original DataFrame Info:\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "\n",
    "# Remove the RecordID column\n",
    "print(\"\\nStep 1: Removing 'RecordID' column...\")\n",
    "if 'RecordID' in data.columns:\n",
    "    data.drop('RecordID', axis=1, inplace=True)\n",
    "    print(\"'RecordID' column removed.\")\n",
    "    print(f\"DataFrame shape after removing RecordID: {data.shape}\")\n",
    "else:\n",
    "    print(\"'RecordID' column not found.\")\n",
    "\n",
    "# Separate features (X) and labels (y_labels)\n",
    "print(\"\\nStep 2: Separating features (X) and labels (y_labels)...\")\n",
    "# Define label columns explicitly\n",
    "label_columns = ['Family', 'Genus', 'Species']\n",
    "# Define feature columns as everything else\n",
    "feature_columns = [col for col in data.columns if col not in label_columns]\n",
    "\n",
    "# Create X (features) - use .copy() to avoid SettingWithCopyWarning later\n",
    "X = data[feature_columns].copy()\n",
    "# Create y_labels (targets) - use .copy()\n",
    "y_labels = data[label_columns].copy()\n",
    "\n",
    "print(f\"Features DataFrame X shape: {X.shape}\")\n",
    "print(f\"Labels DataFrame y_labels shape: {y_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc97e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for and removing duplicate rows based on features (X)...\n",
      "Number of duplicate rows found in features (X): 0\n",
      "No duplicate rows found in features (X).\n"
     ]
    }
   ],
   "source": [
    "# Check for and remove duplicates based on features (X)\n",
    "print(\"\\nChecking for and removing duplicate rows based on features (X)...\")\n",
    "# Check how many duplicate rows exist in X\n",
    "num_duplicates_X = X.duplicated().sum()\n",
    "print(f\"Number of duplicate rows found in features (X): {num_duplicates_X}\")\n",
    "\n",
    "if num_duplicates_X > 0:\n",
    "    # Store original number of rows before removing duplicates\n",
    "    original_count = X.shape[0]\n",
    "\n",
    "    # Get the indices of rows to keep (non-duplicates - keep='first' is default)\n",
    "    # This directly modifies X and keeps the first occurrence\n",
    "    X = X.drop_duplicates(keep='first')\n",
    "\n",
    "    # Crucially, filter y_labels using the index of the de-duplicated X\n",
    "    # .loc is preferred for label-based indexing\n",
    "    y_labels = y_labels.loc[X.index]\n",
    "\n",
    "    removed_count = original_count - X.shape[0]\n",
    "    print(f\"Removed {removed_count} duplicate rows based on feature values.\")\n",
    "    print(f\"New shape of X: {X.shape}\")\n",
    "    print(f\"New shape of y_labels: {y_labels.shape}\")\n",
    "\n",
    "    # Sanity check: Ensure shapes and indices still align\n",
    "    assert X.shape[0] == y_labels.shape[0], \"Row counts of X and y_labels do not match after duplicate removal!\"\n",
    "    assert all(X.index == y_labels.index), \"Indices of X and y_labels do not match after duplicate removal!\"\n",
    "    print(\"X and y_labels successfully aligned after duplicate removal.\")\n",
    "else:\n",
    "    print(\"No duplicate rows found in features (X).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a82773-438f-4acd-bfac-9914fb04a7d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# --- Configuration ---\n",
    "random_state = 42\n",
    "target_columns = ['Family', 'Genus', 'Species'] \n",
    "outlier_strategies = ['Keep', 'Transform', 'Remove']\n",
    "\n",
    "results = []\n",
    "\n",
    "# Ensure Data is Loaded\n",
    "if 'X' not in locals() or 'y_labels' not in locals():\n",
    "    raise NameError(\"CRITICAL: Features 'X' and 'y_labels' are not defined. Please run the data loading cells first.\")\n",
    "\n",
    "print(f\"Starting Baseline Benchmark (KMeans, Spectral, Agglomerative)...\")\n",
    "\n",
    "# --- MASTER LOOP ---\n",
    "for target_col in target_columns:\n",
    "    # 1. Determine n_clusters based on the current target\n",
    "    # Family=4, Genus=8, Species=10\n",
    "    true_labels_full = y_labels[target_col]\n",
    "    n_clusters_current = true_labels_full.nunique()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TARGET: {target_col} (k={n_clusters_current})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    for strategy in outlier_strategies:\n",
    "        X_processed = X.copy()\n",
    "        # We need the specific label column for evaluation\n",
    "        y_processed_current = true_labels_full.copy()\n",
    "\n",
    "        # --- Outlier Handling Logic ---\n",
    "        if strategy == 'Transform':\n",
    "            # Winsorization (Clipping)\n",
    "            Q1 = X_processed.quantile(0.25)\n",
    "            Q3 = X_processed.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            X_processed = X_processed.clip(lower=lower, upper=upper, axis=1)\n",
    "            \n",
    "        elif strategy == 'Remove':\n",
    "            # Identify outliers using IQR\n",
    "            Q1 = X_processed.quantile(0.25)\n",
    "            Q3 = X_processed.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outlier_mask = ((X_processed < (Q1 - 1.5 * IQR)) | (X_processed > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "            \n",
    "            # Filter X and Y (Must keep them aligned)\n",
    "            X_processed = X_processed[~outlier_mask]\n",
    "            y_processed_current = y_processed_current.loc[X_processed.index]\n",
    "            \n",
    "            # Safety check\n",
    "            if len(X_processed) < n_clusters_current:\n",
    "                print(f\"  [Skipping {strategy}]: Too few samples remaining.\")\n",
    "                continue\n",
    "\n",
    "        # --- Scaling ---\n",
    "        # Critical for KMeans and Spectral\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_processed)\n",
    "        n_samples_now = X_processed.shape[0]\n",
    "\n",
    "        # --- Define Baseline Models ---\n",
    "        # Note: n_clusters is set dynamically based on the loop\n",
    "        models = {\n",
    "            'KMeans': KMeans(n_clusters=n_clusters_current, n_init=10, init='random', algorithm='lloyd', max_iter=10, random_state=42),\n",
    "            'Spectral': SpectralClustering(n_clusters=n_clusters_current, random_state=random_state, assign_labels='kmeans', affinity='nearest_neighbors', n_neighbors=20,),\n",
    "            'Agglomerative': AgglomerativeClustering(n_clusters=n_clusters_current, linkage='single', metric='euclidean') \n",
    "        }\n",
    "\n",
    "        print(f\"  Strategy: {strategy:<10} | Samples: {n_samples_now}\")\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            try:\n",
    "                # Fit & Predict\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "                    if hasattr(model, 'fit_predict'):\n",
    "                        labels_pred = model.fit_predict(X_scaled)\n",
    "                    else:\n",
    "                        model.fit(X_scaled)\n",
    "                        labels_pred = model.labels_\n",
    "\n",
    "                # Evaluate\n",
    "                ami = adjusted_mutual_info_score(y_processed_current, labels_pred)\n",
    "                ari = adjusted_rand_score(y_processed_current, labels_pred)\n",
    "                \n",
    "                if len(set(labels_pred)) > 1:\n",
    "                    sil = silhouette_score(X_scaled, labels_pred)\n",
    "                else:\n",
    "                    sil = -1.0\n",
    "\n",
    "                results.append({\n",
    "                    'Target': target_col,\n",
    "                    'k': n_clusters_current,\n",
    "                    'Strategy': strategy,\n",
    "                    'Model': name,\n",
    "                    'AMI': ami,\n",
    "                    'ARI': ari,\n",
    "                    'Silhouette': sil,\n",
    "                    'Samples': n_samples_now\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error in {name}: {e}\")\n",
    "\n",
    "# --- Display Final Results ---\n",
    "results_df = pd.DataFrame(results)\n",
    "# Sort by Target, then AMI to easily see the winner for each category\n",
    "results_df = results_df.sort_values(by=['Target', 'AMI'], ascending=[True, False])\n",
    "\n",
    "print(\"\\n\\n===== BASELINE COMPARISON TABLE =====\")\n",
    "# Displaying specific columns for clarity\n",
    "print(results_df[['Target', 'k', 'Strategy', 'Model', 'AMI', 'ARI', 'Silhouette']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f67a5-76e3-4b0e-b903-7e64e68ab21f",
   "metadata": {},
   "source": [
    "### ===== BASELINE COMPARISON TABLE =====\n",
    " **Target  k  Strategy         Model      AMI      ARI  Silhouette**\n",
    " Family  4    Remove      Spectral 0.617417 0.748328    0.366389\n",
    " Family  4    Remove        KMeans 0.456868 0.395023    0.279076\n",
    " Family  4 Transform      Spectral 0.401701 0.460231    0.220471\n",
    " Family  4 Transform        KMeans 0.380645 0.456086    0.357662\n",
    " Family  4      Keep        KMeans 0.379143 0.458515    0.353109\n",
    " Family  4      Keep      Spectral 0.362204 0.439397    0.301774\n",
    " Family  4    Remove Agglomerative 0.002307 0.001917    0.153302\n",
    " Family  4 Transform Agglomerative 0.000596 0.000731    0.301932\n",
    " Family  4      Keep Agglomerative 0.000279 0.000548    0.541098\n",
    "  Genus  8 Transform      Spectral 0.577039 0.608530    0.285550\n",
    "  Genus  8      Keep      Spectral 0.575417 0.606118    0.272233\n",
    "  Genus  8    Remove      Spectral 0.529336 0.421120    0.241688\n",
    "  Genus  8 Transform        KMeans 0.482677 0.357524    0.275112\n",
    "  Genus  8      Keep        KMeans 0.470258 0.350738    0.289457\n",
    "  Genus  8    Remove        KMeans 0.463141 0.292127    0.215108\n",
    "  Genus  8    Remove Agglomerative 0.008648 0.005363    0.068339\n",
    "  Genus  8      Keep Agglomerative 0.001908 0.001632    0.417414\n",
    "  Genus  8 Transform Agglomerative 0.000824 0.000788    0.183894\n",
    "Species 10    Remove      Spectral 0.669132 0.527300    0.264123\n",
    "Species 10 Transform      Spectral 0.655205 0.597940    0.232617\n",
    "Species 10      Keep      Spectral 0.653009 0.598955    0.215734\n",
    "Species 10      Keep        KMeans 0.639605 0.440660    0.250666\n",
    "Species 10 Transform        KMeans 0.637220 0.543537    0.277363\n",
    "Species 10    Remove        KMeans 0.560339 0.281434    0.216639\n",
    "Species 10    Remove Agglomerative 0.007667 0.005111    0.059209\n",
    "Species 10      Keep Agglomerative 0.001347 0.001043    0.411665\n",
    "Species 10 Transform Agglomerative 0.000970 0.000978    0.174990\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d85822d-a064-4b65-966b-fe005ba8b77a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Custom Model Benchmark...\n",
      "RLAC Grid: 10 methods x 2 r x 2 bw x 2 seeds\n",
      "MDH: Fixed configuration.\n",
      "\n",
      "============================================================\n",
      "TARGET: Species (k=10)\n",
      "============================================================\n",
      "  Strategy: Remove     | Samples: 5416\n",
      "    [RLAC] depth_ratio     | r=JL   | bw=0.1 | s=44 ... [DEPTH_RATIO] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1027 | Score: 0.1191\n",
      "Iter 2: Split Cluster 0 (Size: 227) via Proj 430 | Score: 0.9922\n",
      "Iter 3: Split Cluster 2 (Size: 139) via Proj 1785 | Score: 0.9986\n",
      "Iter 4: Split Cluster 0 (Size: 5189) via Proj 1811 | Score: 0.1139\n",
      "Iter 5: Split Cluster 3 (Size: 281) via Proj 1103 | Score: 0.9827\n",
      "RLAC (depth_ratio) complete. Final clusters: 6\n",
      "Done (AMI: 0.3501)\n",
      "    [RLAC] depth_ratio     | r=JL   | bw=0.1 | s=45 ... [DEPTH_RATIO] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 151 | Score: 0.1191\n",
      "Iter 2: Split Cluster 0 (Size: 227) via Proj 1181 | Score: 0.9968\n",
      "Iter 3: Split Cluster 1 (Size: 139) via Proj 863 | Score: 0.9575\n",
      "Iter 4: Split Cluster 0 (Size: 5189) via Proj 1695 | Score: 0.0618\n",
      "RLAC (depth_ratio) complete. Final clusters: 5\n",
      "Done (AMI: 0.2429)\n",
      "    [RLAC] depth_ratio     | r=JL   | bw=0.2 | s=44 ... [DEPTH_RATIO] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1811 | Score: 0.0930\n",
      "Iter 2: Split Cluster 0 (Size: 281) via Proj 1103 | Score: 0.8604\n",
      "Iter 3: Split Cluster 0 (Size: 5135) via Proj 726 | Score: 0.0603\n",
      "Iter 4: Split Cluster 2 (Size: 5040) via Proj 207 | Score: 0.0343\n",
      "Iter 5: Split Cluster 3 (Size: 4974) via Proj 1899 | Score: 0.0487\n",
      "RLAC (depth_ratio) complete. Final clusters: 6\n",
      "Done (AMI: 0.3484)\n",
      "    [RLAC] depth_ratio     | r=JL   | bw=0.2 | s=45 ... [DEPTH_RATIO] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 151 | Score: 0.0827\n",
      "Iter 2: Split Cluster 0 (Size: 227) via Proj 1489 | Score: 0.9473\n",
      "Iter 3: Split Cluster 2 (Size: 137) via Proj 1180 | Score: 0.9034\n",
      "Iter 4: Split Cluster 0 (Size: 5189) via Proj 1695 | Score: 0.0465\n",
      "RLAC (depth_ratio) complete. Final clusters: 5\n",
      "Done (AMI: 0.2390)\n",
      "    [RLAC] depth_ratio     | r=200  | bw=0.1 | s=44 ... [DEPTH_RATIO] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 144 | Score: 0.0597\n",
      "Iter 2: Split Cluster 0 (Size: 5326) via Proj 29 | Score: 0.0757\n",
      "RLAC (depth_ratio) complete. Final clusters: 3\n",
      "Done (AMI: 0.1677)\n",
      "    [RLAC] depth_ratio     | r=200  | bw=0.1 | s=45 ... [DEPTH_RATIO] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (depth_ratio) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] depth_ratio     | r=200  | bw=0.2 | s=44 ... [DEPTH_RATIO] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 127 | Score: 0.0454\n",
      "Iter 2: Split Cluster 1 (Size: 5321) via Proj 29 | Score: 0.0542\n",
      "RLAC (depth_ratio) complete. Final clusters: 3\n",
      "Done (AMI: 0.1681)\n",
      "    [RLAC] depth_ratio     | r=200  | bw=0.2 | s=45 ... [DEPTH_RATIO] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (depth_ratio) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] dip             | r=JL   | bw=0.1 | s=44 ... [DIP] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1497 | Score: 0.0219\n",
      "Iter 2: Split Cluster 1 (Size: 5322) via Proj 207 | Score: 0.0084\n",
      "Iter 3: Split Cluster 1 (Size: 5256) via Proj 1811 | Score: 0.0068\n",
      "Iter 4: Split Cluster 2 (Size: 281) via Proj 1103 | Score: 0.0617\n",
      "RLAC (dip) complete. Final clusters: 5\n",
      "Done (AMI: 0.3105)\n",
      "    [RLAC] dip             | r=JL   | bw=0.1 | s=45 ... [DIP] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 151 | Score: 0.0037\n",
      "Iter 2: Split Cluster 0 (Size: 227) via Proj 1398 | Score: 0.0976\n",
      "Iter 3: Split Cluster 1 (Size: 138) via Proj 746 | Score: 0.0851\n",
      "Iter 4: Split Cluster 0 (Size: 5189) via Proj 1695 | Score: 0.0107\n",
      "RLAC (dip) complete. Final clusters: 5\n",
      "Done (AMI: 0.2436)\n",
      "    [RLAC] dip             | r=JL   | bw=0.2 | s=44 ... [DIP] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1497 | Score: 0.0219\n",
      "Iter 2: Split Cluster 1 (Size: 5322) via Proj 207 | Score: 0.0084\n",
      "Iter 3: Split Cluster 1 (Size: 5256) via Proj 1811 | Score: 0.0068\n",
      "Iter 4: Split Cluster 2 (Size: 281) via Proj 1103 | Score: 0.0617\n",
      "RLAC (dip) complete. Final clusters: 5\n",
      "Done (AMI: 0.3105)\n",
      "    [RLAC] dip             | r=JL   | bw=0.2 | s=45 ... [DIP] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 151 | Score: 0.0037\n",
      "Iter 2: Split Cluster 0 (Size: 227) via Proj 1398 | Score: 0.0976\n",
      "Iter 3: Split Cluster 1 (Size: 138) via Proj 746 | Score: 0.0851\n",
      "Iter 4: Split Cluster 0 (Size: 5189) via Proj 1695 | Score: 0.0107\n",
      "RLAC (dip) complete. Final clusters: 5\n",
      "Done (AMI: 0.2436)\n",
      "    [RLAC] dip             | r=200  | bw=0.1 | s=44 ... [DIP] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 144 | Score: 0.0094\n",
      "Iter 2: Split Cluster 0 (Size: 5326) via Proj 29 | Score: 0.0045\n",
      "RLAC (dip) complete. Final clusters: 3\n",
      "Done (AMI: 0.1677)\n",
      "    [RLAC] dip             | r=200  | bw=0.1 | s=45 ... [DIP] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (dip) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] dip             | r=200  | bw=0.2 | s=44 ... [DIP] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 144 | Score: 0.0094\n",
      "Iter 2: Split Cluster 0 (Size: 5326) via Proj 29 | Score: 0.0045\n",
      "RLAC (dip) complete. Final clusters: 3\n",
      "Done (AMI: 0.1677)\n",
      "    [RLAC] dip             | r=200  | bw=0.2 | s=45 ... [DIP] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (dip) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] holes           | r=JL   | bw=0.1 | s=44 ... [HOLES] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (holes) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] holes           | r=JL   | bw=0.1 | s=45 ... [HOLES] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (holes) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] holes           | r=JL   | bw=0.2 | s=44 ... [HOLES] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (holes) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] holes           | r=JL   | bw=0.2 | s=45 ... [HOLES] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (holes) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] holes           | r=200  | bw=0.1 | s=44 ... [HOLES] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (holes) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] holes           | r=200  | bw=0.1 | s=45 ... [HOLES] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (holes) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] holes           | r=200  | bw=0.2 | s=44 ... [HOLES] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (holes) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] holes           | r=200  | bw=0.2 | s=45 ... [HOLES] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (holes) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] min_kurt        | r=JL   | bw=0.1 | s=44 ... [MIN_KURT] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1497 | Score: -0.4284\n",
      "Iter 2: Split Cluster 1 (Size: 5322) via Proj 207 | Score: -1.1796\n",
      "Iter 3: Split Cluster 1 (Size: 5256) via Proj 1811 | Score: -3.3713\n",
      "Iter 4: Split Cluster 2 (Size: 281) via Proj 294 | Score: 1.2782\n",
      "RLAC (min_kurt) complete. Final clusters: 5\n",
      "Done (AMI: 0.3087)\n",
      "    [RLAC] min_kurt        | r=JL   | bw=0.1 | s=45 ... [MIN_KURT] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 151 | Score: -1.6136\n",
      "Iter 2: Split Cluster 0 (Size: 227) via Proj 1398 | Score: 1.6139\n",
      "Iter 3: Split Cluster 1 (Size: 138) via Proj 746 | Score: 1.5000\n",
      "Iter 4: Split Cluster 0 (Size: 5189) via Proj 1695 | Score: -0.9989\n",
      "RLAC (min_kurt) complete. Final clusters: 5\n",
      "Done (AMI: 0.2436)\n",
      "    [RLAC] min_kurt        | r=JL   | bw=0.2 | s=44 ... [MIN_KURT] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1497 | Score: -0.4284\n",
      "Iter 2: Split Cluster 1 (Size: 5322) via Proj 207 | Score: -1.1796\n",
      "Iter 3: Split Cluster 1 (Size: 5256) via Proj 1811 | Score: -3.3713\n",
      "Iter 4: Split Cluster 2 (Size: 281) via Proj 294 | Score: 1.2782\n",
      "RLAC (min_kurt) complete. Final clusters: 5\n",
      "Done (AMI: 0.3093)\n",
      "    [RLAC] min_kurt        | r=JL   | bw=0.2 | s=45 ... [MIN_KURT] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 151 | Score: -1.6136\n",
      "Iter 2: Split Cluster 0 (Size: 227) via Proj 1398 | Score: 1.6139\n",
      "Iter 3: Split Cluster 1 (Size: 138) via Proj 746 | Score: 1.5000\n",
      "Iter 4: Split Cluster 0 (Size: 5189) via Proj 1695 | Score: -0.9989\n",
      "RLAC (min_kurt) complete. Final clusters: 5\n",
      "Done (AMI: 0.2436)\n",
      "    [RLAC] min_kurt        | r=200  | bw=0.1 | s=44 ... [MIN_KURT] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 144 | Score: -4.1292\n",
      "Iter 2: Split Cluster 0 (Size: 5326) via Proj 29 | Score: -2.0124\n",
      "RLAC (min_kurt) complete. Final clusters: 3\n",
      "Done (AMI: 0.1677)\n",
      "    [RLAC] min_kurt        | r=200  | bw=0.1 | s=45 ... [MIN_KURT] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (min_kurt) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] min_kurt        | r=200  | bw=0.2 | s=44 ... [MIN_KURT] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 144 | Score: -4.1292\n",
      "Iter 2: Split Cluster 0 (Size: 5326) via Proj 29 | Score: -2.0124\n",
      "RLAC (min_kurt) complete. Final clusters: 3\n",
      "Done (AMI: 0.1677)\n",
      "    [RLAC] min_kurt        | r=200  | bw=0.2 | s=45 ... [MIN_KURT] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (min_kurt) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] max_kurt        | r=JL   | bw=0.1 | s=44 ... [MAX_KURT] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 672 | Score: 6.9768\n",
      "Iter 2: Split Cluster 1 (Size: 5323) via Proj 1811 | Score: 3.4117\n",
      "Iter 3: Split Cluster 2 (Size: 5042) via Proj 466 | Score: 2.3331\n",
      "Iter 4: Split Cluster 2 (Size: 4984) via Proj 207 | Score: 1.2886\n",
      "Iter 5: Split Cluster 1 (Size: 281) via Proj 1922 | Score: 0.2606\n",
      "RLAC (max_kurt) complete. Final clusters: 6\n",
      "Done (AMI: 0.3394)\n",
      "    [RLAC] max_kurt        | r=JL   | bw=0.1 | s=45 ... [MAX_KURT] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 5.8116\n",
      "RLAC (max_kurt) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] max_kurt        | r=JL   | bw=0.2 | s=44 ... [MAX_KURT] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 672 | Score: 6.9768\n",
      "Iter 2: Split Cluster 1 (Size: 5323) via Proj 1811 | Score: 3.4117\n",
      "Iter 3: Split Cluster 2 (Size: 5042) via Proj 466 | Score: 2.3331\n",
      "Iter 4: Split Cluster 2 (Size: 4984) via Proj 207 | Score: 1.2886\n",
      "Iter 5: Split Cluster 1 (Size: 281) via Proj 1922 | Score: 0.2606\n",
      "RLAC (max_kurt) complete. Final clusters: 6\n",
      "Done (AMI: 0.3394)\n",
      "    [RLAC] max_kurt        | r=JL   | bw=0.2 | s=45 ... [MAX_KURT] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 5.8116\n",
      "RLAC (max_kurt) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] max_kurt        | r=200  | bw=0.1 | s=44 ... [MAX_KURT] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 5.8129\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 2.0138\n",
      "RLAC (max_kurt) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] max_kurt        | r=200  | bw=0.1 | s=45 ... [MAX_KURT] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (max_kurt) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] max_kurt        | r=200  | bw=0.2 | s=44 ... [MAX_KURT] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 5.8129\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 2.0138\n",
      "RLAC (max_kurt) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] max_kurt        | r=200  | bw=0.2 | s=45 ... [MAX_KURT] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (max_kurt) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] negentropy      | r=JL   | bw=0.1 | s=44 ... [NEGENTROPY] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1497 | Score: 0.3715\n",
      "Iter 2: Split Cluster 1 (Size: 5322) via Proj 1811 | Score: 0.2128\n",
      "Iter 3: Split Cluster 1 (Size: 281) via Proj 1922 | Score: 0.5008\n",
      "Iter 4: Split Cluster 1 (Size: 5041) via Proj 207 | Score: 0.2212\n",
      "RLAC (negentropy) complete. Final clusters: 5\n",
      "Done (AMI: 0.3141)\n",
      "    [RLAC] negentropy      | r=JL   | bw=0.1 | s=45 ... [NEGENTROPY] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 0.1696\n",
      "RLAC (negentropy) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] negentropy      | r=JL   | bw=0.2 | s=44 ... [NEGENTROPY] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1497 | Score: 0.3639\n",
      "Iter 2: Split Cluster 1 (Size: 5322) via Proj 1811 | Score: 0.2039\n",
      "Iter 3: Split Cluster 1 (Size: 281) via Proj 1922 | Score: 0.4307\n",
      "Iter 4: Split Cluster 1 (Size: 5041) via Proj 207 | Score: 0.2127\n",
      "RLAC (negentropy) complete. Final clusters: 5\n",
      "Done (AMI: 0.3141)\n",
      "    [RLAC] negentropy      | r=JL   | bw=0.2 | s=45 ... [NEGENTROPY] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 0.1595\n",
      "RLAC (negentropy) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] negentropy      | r=200  | bw=0.1 | s=44 ... [NEGENTROPY] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 0.2187\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 0.1190\n",
      "RLAC (negentropy) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] negentropy      | r=200  | bw=0.1 | s=45 ... [NEGENTROPY] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (negentropy) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] negentropy      | r=200  | bw=0.2 | s=44 ... [NEGENTROPY] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 0.2079\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 0.1115\n",
      "RLAC (negentropy) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] negentropy      | r=200  | bw=0.2 | s=45 ... [NEGENTROPY] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (negentropy) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] skewness        | r=JL   | bw=0.1 | s=44 ... [SKEWNESS] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 672 | Score: 1.6786\n",
      "Iter 2: Split Cluster 1 (Size: 5323) via Proj 1811 | Score: 1.2789\n",
      "Iter 3: Split Cluster 1 (Size: 281) via Proj 1922 | Score: 1.1251\n",
      "Iter 4: Split Cluster 1 (Size: 5042) via Proj 207 | Score: 1.0652\n",
      "Iter 5: Split Cluster 3 (Size: 4976) via Proj 466 | Score: 0.9119\n",
      "RLAC (skewness) complete. Final clusters: 6\n",
      "Done (AMI: 0.3394)\n",
      "    [RLAC] skewness        | r=JL   | bw=0.1 | s=45 ... [SKEWNESS] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 1.5769\n",
      "RLAC (skewness) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] skewness        | r=JL   | bw=0.2 | s=44 ... [SKEWNESS] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 672 | Score: 1.6786\n",
      "Iter 2: Split Cluster 1 (Size: 5323) via Proj 1811 | Score: 1.2789\n",
      "Iter 3: Split Cluster 1 (Size: 281) via Proj 1922 | Score: 1.1251\n",
      "Iter 4: Split Cluster 1 (Size: 5042) via Proj 207 | Score: 1.0652\n",
      "Iter 5: Split Cluster 3 (Size: 4976) via Proj 466 | Score: 0.9119\n",
      "RLAC (skewness) complete. Final clusters: 6\n",
      "Done (AMI: 0.3394)\n",
      "    [RLAC] skewness        | r=JL   | bw=0.2 | s=45 ... [SKEWNESS] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 1.5769\n",
      "RLAC (skewness) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] skewness        | r=200  | bw=0.1 | s=44 ... [SKEWNESS] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 1.5889\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 1.0206\n",
      "RLAC (skewness) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] skewness        | r=200  | bw=0.1 | s=45 ... [SKEWNESS] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (skewness) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] skewness        | r=200  | bw=0.2 | s=44 ... [SKEWNESS] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 1.5889\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 1.0206\n",
      "RLAC (skewness) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] skewness        | r=200  | bw=0.2 | s=45 ... [SKEWNESS] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (skewness) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] fisher          | r=JL   | bw=0.1 | s=44 ... [FISHER] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1168 | Score: 21.3352\n",
      "Iter 2: Split Cluster 1 (Size: 5323) via Proj 207 | Score: 15.0010\n",
      "Iter 3: Split Cluster 1 (Size: 5257) via Proj 1811 | Score: 14.2629\n",
      "Iter 4: Split Cluster 2 (Size: 281) via Proj 1563 | Score: 12.4445\n",
      "RLAC (fisher) complete. Final clusters: 5\n",
      "Done (AMI: 0.3091)\n",
      "    [RLAC] fisher          | r=JL   | bw=0.1 | s=45 ... [FISHER] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 23.0775\n",
      "RLAC (fisher) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] fisher          | r=JL   | bw=0.2 | s=44 ... [FISHER] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1168 | Score: 21.3352\n",
      "Iter 2: Split Cluster 1 (Size: 5323) via Proj 207 | Score: 15.0010\n",
      "Iter 3: Split Cluster 1 (Size: 5257) via Proj 1811 | Score: 14.2629\n",
      "Iter 4: Split Cluster 2 (Size: 281) via Proj 1946 | Score: 12.6758\n",
      "RLAC (fisher) complete. Final clusters: 5\n",
      "Done (AMI: 0.3143)\n",
      "    [RLAC] fisher          | r=JL   | bw=0.2 | s=45 ... [FISHER] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 23.0775\n",
      "RLAC (fisher) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] fisher          | r=200  | bw=0.1 | s=44 ... [FISHER] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 144 | Score: 22.9914\n",
      "Iter 2: Split Cluster 0 (Size: 5326) via Proj 29 | Score: 15.5079\n",
      "RLAC (fisher) complete. Final clusters: 3\n",
      "Done (AMI: 0.1677)\n",
      "    [RLAC] fisher          | r=200  | bw=0.1 | s=45 ... [FISHER] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (fisher) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] fisher          | r=200  | bw=0.2 | s=44 ... [FISHER] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 144 | Score: 22.9914\n",
      "Iter 2: Split Cluster 0 (Size: 5326) via Proj 29 | Score: 15.5079\n",
      "RLAC (fisher) complete. Final clusters: 3\n",
      "Done (AMI: 0.1677)\n",
      "    [RLAC] fisher          | r=200  | bw=0.2 | s=45 ... [FISHER] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (fisher) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] hermite         | r=JL   | bw=0.1 | s=44 ... [HERMITE] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 672 | Score: 51.3494\n",
      "Iter 2: Split Cluster 1 (Size: 5323) via Proj 1811 | Score: 13.2352\n",
      "Iter 3: Split Cluster 2 (Size: 5042) via Proj 466 | Score: 6.0690\n",
      "Iter 4: Split Cluster 2 (Size: 4984) via Proj 207 | Score: 2.8669\n",
      "Iter 5: Split Cluster 1 (Size: 281) via Proj 294 | Score: 1.7536\n",
      "RLAC (hermite) complete. Final clusters: 6\n",
      "Done (AMI: 0.3341)\n",
      "    [RLAC] hermite         | r=JL   | bw=0.1 | s=45 ... [HERMITE] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 36.1581\n",
      "RLAC (hermite) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] hermite         | r=JL   | bw=0.2 | s=44 ... [HERMITE] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 672 | Score: 51.3494\n",
      "Iter 2: Split Cluster 1 (Size: 5323) via Proj 1811 | Score: 13.2352\n",
      "Iter 3: Split Cluster 2 (Size: 5042) via Proj 466 | Score: 6.0690\n",
      "Iter 4: Split Cluster 2 (Size: 4984) via Proj 207 | Score: 2.8669\n",
      "Iter 5: Split Cluster 1 (Size: 281) via Proj 294 | Score: 1.7536\n",
      "RLAC (hermite) complete. Final clusters: 6\n",
      "Done (AMI: 0.3347)\n",
      "    [RLAC] hermite         | r=JL   | bw=0.2 | s=45 ... [HERMITE] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1772 | Score: 36.1581\n",
      "RLAC (hermite) complete. Final clusters: 2\n",
      "Done (AMI: 0.0825)\n",
      "    [RLAC] hermite         | r=200  | bw=0.1 | s=44 ... [HERMITE] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 36.2111\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 5.0805\n",
      "RLAC (hermite) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] hermite         | r=200  | bw=0.1 | s=45 ... [HERMITE] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (hermite) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] hermite         | r=200  | bw=0.2 | s=44 ... [HERMITE] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 36.2111\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 5.0805\n",
      "RLAC (hermite) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] hermite         | r=200  | bw=0.2 | s=45 ... [HERMITE] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (hermite) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] friedman_tukey  | r=JL   | bw=0.1 | s=44 ... [FRIEDMAN_TUKEY] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1497 | Score: 1081.7991\n",
      "Iter 2: Split Cluster 1 (Size: 5322) via Proj 1811 | Score: 826.1102\n",
      "Iter 3: Split Cluster 2 (Size: 5041) via Proj 207 | Score: 787.7239\n",
      "Iter 4: Split Cluster 1 (Size: 281) via Proj 1922 | Score: 78.6857\n",
      "RLAC (friedman_tukey) complete. Final clusters: 5\n",
      "Done (AMI: 0.3141)\n",
      "    [RLAC] friedman_tukey  | r=JL   | bw=0.1 | s=45 ... [FRIEDMAN_TUKEY] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1910 | Score: 813.7802\n",
      "Iter 2: Split Cluster 0 (Size: 5316) via Proj 28 | Score: 863.2408\n",
      "RLAC (friedman_tukey) complete. Final clusters: 3\n",
      "Done (AMI: 0.1688)\n",
      "    [RLAC] friedman_tukey  | r=JL   | bw=0.2 | s=44 ... [FRIEDMAN_TUKEY] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1497 | Score: 1081.7991\n",
      "Iter 2: Split Cluster 1 (Size: 5322) via Proj 1811 | Score: 826.1102\n",
      "Iter 3: Split Cluster 2 (Size: 5041) via Proj 207 | Score: 787.7239\n",
      "Iter 4: Split Cluster 1 (Size: 281) via Proj 1922 | Score: 78.6857\n",
      "RLAC (friedman_tukey) complete. Final clusters: 5\n",
      "Done (AMI: 0.3141)\n",
      "    [RLAC] friedman_tukey  | r=JL   | bw=0.2 | s=45 ... [FRIEDMAN_TUKEY] Generating 1983 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 1910 | Score: 813.7802\n",
      "RLAC (friedman_tukey) complete. Final clusters: 2\n",
      "Done (AMI: 0.0822)\n",
      "    [RLAC] friedman_tukey  | r=200  | bw=0.1 | s=44 ... [FRIEDMAN_TUKEY] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 899.5356\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 701.6084\n",
      "RLAC (friedman_tukey) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] friedman_tukey  | r=200  | bw=0.1 | s=45 ... [FRIEDMAN_TUKEY] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (friedman_tukey) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "    [RLAC] friedman_tukey  | r=200  | bw=0.2 | s=44 ... [FRIEDMAN_TUKEY] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "Iter 1: Split Cluster 0 (Size: 5416) via Proj 53 | Score: 899.5356\n",
      "Iter 2: Split Cluster 0 (Size: 5322) via Proj 29 | Score: 701.6084\n",
      "RLAC (friedman_tukey) complete. Final clusters: 3\n",
      "Done (AMI: 0.1662)\n",
      "    [RLAC] friedman_tukey  | r=200  | bw=0.2 | s=45 ... [FRIEDMAN_TUKEY] Generating 200 sparse random projections...\n",
      "Starting Clustering: Target=10 clusters.\n",
      "RLAC (friedman_tukey) complete. Final clusters: 1\n",
      "Done (AMI: 0.0000)\n",
      "Done (AMI: 0.5214)d        | h=1.0 | a=0.9 | s=42 ... \n",
      "\n",
      "\n",
      "===== TOP RLAC CONFIGURATIONS (Sorted by AMI) =====\n",
      " Target Strategy         Method             Params      AMI      ARI\n",
      "Species   Remove    depth_ratio r=JL, bw=0.1, s=44 0.350064 0.243424\n",
      "Species   Remove    depth_ratio r=JL, bw=0.2, s=44 0.348379 0.240283\n",
      "Species   Remove       max_kurt r=JL, bw=0.1, s=44 0.339392 0.237167\n",
      "Species   Remove       max_kurt r=JL, bw=0.2, s=44 0.339392 0.237167\n",
      "Species   Remove       skewness r=JL, bw=0.1, s=44 0.339392 0.237167\n",
      "Species   Remove       skewness r=JL, bw=0.2, s=44 0.339392 0.237167\n",
      "Species   Remove        hermite r=JL, bw=0.2, s=44 0.334670 0.237173\n",
      "Species   Remove        hermite r=JL, bw=0.1, s=44 0.334132 0.237143\n",
      "Species   Remove         fisher r=JL, bw=0.2, s=44 0.314293 0.210177\n",
      "Species   Remove     negentropy r=JL, bw=0.1, s=44 0.314078 0.210531\n",
      "Species   Remove friedman_tukey r=JL, bw=0.1, s=44 0.314078 0.210531\n",
      "Species   Remove friedman_tukey r=JL, bw=0.2, s=44 0.314078 0.210531\n",
      "Species   Remove     negentropy r=JL, bw=0.2, s=44 0.314078 0.210531\n",
      "Species   Remove            dip r=JL, bw=0.2, s=44 0.310473 0.210577\n",
      "Species   Remove            dip r=JL, bw=0.1, s=44 0.310473 0.210577\n",
      "Species   Remove       min_kurt r=JL, bw=0.2, s=44 0.309269 0.210535\n",
      "Species   Remove         fisher r=JL, bw=0.1, s=44 0.309111 0.209879\n",
      "Species   Remove       min_kurt r=JL, bw=0.1, s=44 0.308715 0.210504\n",
      "Species   Remove            dip r=JL, bw=0.1, s=45 0.243631 0.138655\n",
      "Species   Remove            dip r=JL, bw=0.2, s=45 0.243631 0.138655\n",
      "\n",
      "\n",
      "===== MDH RESULTS =====\n",
      " Target Strategy     AMI      ARI\n",
      "Species   Remove 0.52136 0.198706\n"
     ]
    }
   ],
   "source": [
    "import diptest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, silhouette_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Import your custom models\n",
    "from rlac import RLAC\n",
    "from mdh import MDH\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "target_columns = ['Species'] \n",
    "outlier_strategies = ['Remove']\n",
    "\n",
    "# RLAC GRID SEARCH PARAMETERS\n",
    "rlac_methods = [\n",
    "    'depth_ratio', 'dip', 'holes', 'min_kurt', 'max_kurt', \n",
    "    'negentropy', 'skewness', 'fisher', 'hermite', 'friedman_tukey'\n",
    "]\n",
    "rlac_grid = {\n",
    "    'random_state': [44, 45],\n",
    "    'bw_adjust': [0.1, 0.2],\n",
    "    'r': [None, 200]\n",
    "}\n",
    "\n",
    "# MDH FIXED PARAMETERS\n",
    "mdh_params = {\n",
    "    \"h_multiplier\": 1.0,\n",
    "    \"alphamax_val\": 0.9,\n",
    "    \"alpha_steps\": 5,      \n",
    "    \"verbose\": False,      \n",
    "    \"plot\": False          \n",
    "}\n",
    "mdh_seed = 42 \n",
    "\n",
    "custom_results = []\n",
    "\n",
    "# Validate Data Loading\n",
    "if 'X' not in locals() or 'y_labels' not in locals():\n",
    "    raise NameError(\"CRITICAL: Features 'X' and 'y_labels' are not defined.\")\n",
    "\n",
    "print(f\"Starting Custom Model Benchmark...\")\n",
    "print(f\"RLAC Grid: {len(rlac_methods)} methods x {len(rlac_grid['r'])} r x {len(rlac_grid['bw_adjust'])} bw x {len(rlac_grid['random_state'])} seeds\")\n",
    "print(f\"MDH: Fixed configuration.\")\n",
    "\n",
    "# --- MASTER LOOP ---\n",
    "for target_col in target_columns:\n",
    "    true_labels_full = y_labels[target_col]\n",
    "    n_clusters_current = true_labels_full.nunique()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TARGET: {target_col} (k={n_clusters_current})\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    for strategy in outlier_strategies:\n",
    "        X_processed = X.copy()\n",
    "        y_processed_current = true_labels_full.copy()\n",
    "\n",
    "        # --- Outlier Handling ---\n",
    "        if strategy == 'Transform':\n",
    "            Q1 = X_processed.quantile(0.25); Q3 = X_processed.quantile(0.75); IQR = Q3 - Q1\n",
    "            X_processed = X_processed.clip(lower=Q1 - 1.5*IQR, upper=Q3 + 1.5*IQR, axis=1)\n",
    "            \n",
    "        elif strategy == 'Remove':\n",
    "            Q1 = X_processed.quantile(0.25); Q3 = X_processed.quantile(0.75); IQR = Q3 - Q1\n",
    "            outlier_mask = ((X_processed < (Q1 - 1.5*IQR)) | (X_processed > (Q3 + 1.5*IQR))).any(axis=1)\n",
    "            X_processed = X_processed[~outlier_mask]\n",
    "            y_processed_current = y_processed_current.loc[X_processed.index]\n",
    "            \n",
    "            if len(X_processed) < n_clusters_current:\n",
    "                print(f\"  [Skipping {strategy}]: Too few samples.\")\n",
    "                continue\n",
    "\n",
    "        # --- Scaling ---\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_processed)\n",
    "        n_samples_now = X_processed.shape[0]\n",
    "        \n",
    "        print(f\"  Strategy: {strategy:<10} | Samples: {n_samples_now}\")\n",
    "\n",
    "        # ==========================================\n",
    "        # 1. RLAC GRID SEARCH\n",
    "        # ==========================================\n",
    "        for method in rlac_methods:\n",
    "            for r_val in rlac_grid['r']:\n",
    "                for bw in rlac_grid['bw_adjust']:\n",
    "                    for seed in rlac_grid['random_state']:\n",
    "                        \n",
    "                        # LOGGING: Print exactly what we are testing\n",
    "                        r_str = \"JL\" if r_val is None else str(r_val)\n",
    "                        print(f\"    [RLAC] {method:<15} | r={r_str:<4} | bw={bw} | s={seed} ... \", end=\"\")\n",
    "                        \n",
    "                        try:\n",
    "                            # Instantiate\n",
    "                            model = RLAC(\n",
    "                                n_clusters=n_clusters_current,\n",
    "                                method=method,\n",
    "                                r=r_val,\n",
    "                                bw_adjust=bw,\n",
    "                                random_state=seed,\n",
    "                                plot=False\n",
    "                            )\n",
    "                            \n",
    "                            # Fit\n",
    "                            with warnings.catch_warnings():\n",
    "                                warnings.filterwarnings(\"ignore\", category=UserWarning) # Suppress \"Stopping early\" warnings for clean output\n",
    "                                model.fit(X_scaled)\n",
    "                            \n",
    "                            # Evaluate\n",
    "                            ami = adjusted_mutual_info_score(y_processed_current, model.labels_)\n",
    "                            ari = adjusted_rand_score(y_processed_current, model.labels_)\n",
    "                            \n",
    "                            custom_results.append({\n",
    "                                'Target': target_col, 'k': n_clusters_current, 'Strategy': strategy,\n",
    "                                'Model': 'RLAC', 'Method': method,\n",
    "                                'Params': f\"r={r_str}, bw={bw}, s={seed}\",\n",
    "                                'AMI': ami, 'ARI': ari\n",
    "                            })\n",
    "                            print(f\"Done (AMI: {ami:.4f})\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"FAILED. Error: {str(e)[:50]}...\") # Print error if it fails\n",
    "\n",
    "        # ==========================================\n",
    "        # 2. MDH SINGLE RUN\n",
    "        # ==========================================\n",
    "        print(f\"    [MDH]  Standard        | h=1.0 | a=0.9 | s={mdh_seed} ... \", end=\"\")\n",
    "        try:\n",
    "            model = MDH(\n",
    "                n_clusters=n_clusters_current,\n",
    "                h_multiplier=mdh_params['h_multiplier'],\n",
    "                alphamax_val=mdh_params['alphamax_val'],\n",
    "                alpha_steps=mdh_params['alpha_steps'],\n",
    "                random_state=mdh_seed,\n",
    "                verbose=mdh_params['verbose'],\n",
    "                plot=mdh_params['plot']\n",
    "            )\n",
    "            \n",
    "            model.fit(X_scaled)\n",
    "            \n",
    "            ami = adjusted_mutual_info_score(y_processed_current, model.labels_)\n",
    "            ari = adjusted_rand_score(y_processed_current, model.labels_)\n",
    "            \n",
    "            custom_results.append({\n",
    "                'Target': target_col, 'k': n_clusters_current, 'Strategy': strategy,\n",
    "                'Model': 'MDH', 'Method': 'Standard',\n",
    "                'Params': \"Fixed\",\n",
    "                'AMI': ami, 'ARI': ari\n",
    "            })\n",
    "            print(f\"Done (AMI: {ami:.4f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"FAILED. Error: {e}\")\n",
    "\n",
    "# --- DISPLAY TOP RESULTS ---\n",
    "custom_df = pd.DataFrame(custom_results)\n",
    "\n",
    "print(\"\\n\\n===== TOP RLAC CONFIGURATIONS (Sorted by AMI) =====\")\n",
    "if not custom_df.empty:\n",
    "    rlac_df = custom_df[custom_df['Model'] == 'RLAC'].sort_values(by='AMI', ascending=False)\n",
    "    # Showing top 20 to avoid flooding the console, change head() if you want more\n",
    "    print(rlac_df[['Target', 'Strategy', 'Method', 'Params', 'AMI', 'ARI']].head(20).to_string(index=False))\n",
    "\n",
    "    print(\"\\n\\n===== MDH RESULTS =====\")\n",
    "    mdh_df = custom_df[custom_df['Model'] == 'MDH'].sort_values(by='AMI', ascending=False)\n",
    "    print(mdh_df[['Target', 'Strategy', 'AMI', 'ARI']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No results collected. Check for errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4eaeb-93bb-40de-b03d-4108f2724973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68c4f4-ffcf-4b08-88fa-fcec96759d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd59a6-7cee-44fe-9118-16405b22d164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
